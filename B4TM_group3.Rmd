---
title: "B4TM_project"
author: "Timo Dijkstra, Tessa Duk, Mickey van Immerseel, Robin Pocornie"
date: "2-4-2021"
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), out_dir, 'index.html'))})
---

# Load packages
```{r}
library("tidyverse")
library("caret")
```

# Load data
Store all the data as tibble. 
Make an additional tibble for the DNA region information. The ID is in the format <chromosome>.<#feature>
```{r}
train_data_array_input <- as.tibble(read.table(file = "data/Train_call.txt", header = T, sep = "\t"))

target_data_array <- read_tsv(file = "data/Train_clinical.txt")

Instances <- colnames(train_data_array_input)[-c(1:4)]

feature_information <- as_tibble(t(train_data_array_input[,1:4]))
names(feature_information) <- paste(train_data_array_input$Chromosome, ".", as.character(1:dim(train_data_array_input)[1]), sep = "")

DNA_region_information <- c("Chromosome", "Start", "End", "Nclone")
rownames(feature_information) <- DNA_region_information

```


# Data pre-processing
Transpose the train data matrix.
Remove the DNA region information.
Make the DNA_IDs the new feature names.
```{r}
train_data_array <- as_tibble(t(subset(train_data_array_input, select = -c(Chromosome:Nclone))))
names(train_data_array) <- colnames(feature_information)
train_data_array <-  train_data_array %>% add_column(Instances, .before = "1.1")
```
Add the targets to the train_data_arry. 
For convenience, place the targets in front of the train data set.
```{r}
train_data_array <- train_data_array %>% add_column(target_data_array$Subgroup, .before = "1.1")
train_data_array <- train_data_array %>% rename(Target = "target_data_array$Subgroup")

```


# Feature selection
Split the data in a training set with features and a training set with targets (predictions).
Transform the training set to a data frame.
Transform the targets to an object of class "factor".
```{r}
train_x <- select(train_data_array, -Target)
train_y <- select(train_data_array, -c(3:dim(train_data_array)[2]))

train_x_df <- as.data.frame(select(train_data_array, -c(Instances, Target)))
rownames(train_x_df) <- Instances

train_y_df <- as.data.frame(select(train_data_array, -c(3:dim(train_data_array)[2], Instances)))
rownames(train_y_df) <- Instances

train_y_df_factor <- as.factor(train_y_df$Target)

```

Apply the filterVarImp function to determine the most important features.
This gives us a vector of AUC scores for every variable.
Calculate the sum of AUC scores and calculate the sum of squares of AUC scores.
```{r}
rocVarImp <- filterVarImp(train_x_df, train_y_df_factor)
rocVarImp$Sum <- apply(rocVarImp, 1, sum)
rocVarImp$SSQ <- apply(rocVarImp[1:3], 1, function(x){sum(x^2)})
```

## Plot feature importance
Plot the distribution of AUC scores for all the features using the sum of AUCs.
DNA region 17.2185 has the highest score.
http://www.ensembl.org/Homo_sapiens/Location/Overview?r=17:35076296-35282086;db=core
```{r}
auc_scores_per_chromosome <- ggplot(data = rocVarImp, mapping = aes(1:2834, rocVarImp[,4], color = as.factor(train_data_array_input$Chromosome))) +
  geom_point() +
  labs(title = "Feature importance",
       caption = "Sum of AUC scores",
       x = "Feature number",
       y = "Cumulative score")
auc_scores_per_chromosome <- auc_scores_per_chromosome + guides(color=guide_legend(title = "Chromosome"))
auc_scores_per_chromosome 
```

Plot a histogram of AUC scores of the features using the sum of AUCs..
```{r}
auc_scores_histogram <- ggplot(data = rocVarImp, mapping = aes(rocVarImp[,4], color = as.factor(train_data_array_input$Chromosome))) +
  geom_histogram(bins = 30, fill = "white") +
  labs(title = "Feature importance",
       caption = "Sum of AUC scores",
       x = "Cumulative score",
       y = "Frequency")
auc_scores_histogram <- auc_scores_histogram + guides(color=guide_legend(title = "Chromosome"))
auc_scores_histogram 
```

Plot the distribution of AUC scores for all the features using the sum of squares of AUCs.
DNA region 17.2185 has the highest score.
http://www.ensembl.org/Homo_sapiens/Location/Overview?r=17:35076296-35282086;db=core
```{r}
auc_scores_per_chromosome <- ggplot(data = rocVarImp, mapping = aes(1:2834, rocVarImp[,5], color = as.factor(train_data_array_input$Chromosome))) +
  geom_point() +
  labs(title = "Feature importance",
       caption = "Sum of square AUC scores",
       x = "Feature number",
       y = "Cumulative score")
auc_scores_per_chromosome <- auc_scores_per_chromosome + guides(color=guide_legend(title = "Chromosome"))
auc_scores_per_chromosome 
```

Plot a histogram of AUC scores of the features using the sum of squares of AUCs..
```{r}
auc_scores_histogram <- ggplot(data = rocVarImp, mapping = aes(rocVarImp[,5], color = as.factor(train_data_array_input$Chromosome))) +
  geom_histogram(bins = 30, fill = "white") +
  labs(title = "Feature importance",
       caption = "Sum of square AUC scores",
       x = "Cumulative score",
       y = "Frequency")
auc_scores_histogram <- auc_scores_histogram + guides(color=guide_legend(title = "Chromosome"))
auc_scores_histogram 
```


# Cross validation and model training
Convert the rocVarImp data frame to a decreasing feature order.
```{r}
rocVarImp_descending_sum <- rocVarImp[order(rocVarImp$Sum, decreasing = T),]
rocVarImp_descending_ssq <- rocVarImp[order(rocVarImp$SSQ, decreasing = T),]
```


## kNN model
train_data_array[,c(rownames(rocVarImp_descending_ssq)[1])]
Train a kNN with different training set sizes.
First, define a set of parameters: the seed, number of top features to test, the feature column names plus the target column name to extract, a list that stores the knn models, the cross-validation scheme, the metric for model comparison, the grid search parameters, and the grid search scheme.
Then, determine for every set of features {1, ..., 10} the best model by grid search.
```{r}
set.seed(100)
n_features <- 20
tmp_feature_columns <- c(seq(1,n_features), "Target")
kNN_models <- vector(mode = "list", length = n_features)
control <- trainControl(method = "cv", number = 5)
metric <- "Accuracy"
k_grid_search <- seq(3,20)
grid_knn <- expand.grid(k=k_grid_search)


for(i in 1:n_features){
  tmp_feature_columns[i] <- rownames(rocVarImp_descending_ssq)[i]
  fit.knn <- train(Target~., 
                   data=train_data_array[,tmp_feature_columns[c(1:i,length(tmp_feature_columns))]], 
                   method="knn", metric=metric, 
                   trControl=control, 
                   tuneGrid = grid_knn)
  kNN_models[[i]] <- fit.knn
}
```


Format the knn_models output
Add an additional column to describe the number of features used in the model.
Make a table with the performances of all the models.
Make a table with the best scoring models.
Expand these tables using a loop and rbind. For the table with all the models, just add the rows to the table. For the best models, order the knn_model results by decreasing accuracy. Then take the first row and add this row to the table.
Plot the performances by ggplot and highlight the best performing models.
```{r, fig.width=10, fig.height=6}
kNN_models[[1]]$results$n_features <- 1
performance_knn <- kNN_models[[1]]$results

best_knn_models <- kNN_models[[1]]$results[order(kNN_models[[1]]$results$Accuracy, decreasing = T),][1,]

for(i in 2:n_features){
  kNN_models[[i]]$results$n_features <- i
  performance_knn <- rbind(performance_knn, kNN_models[[i]]$results)
  tmp_best_model <- kNN_models[[i]]$results[order(kNN_models[[i]]$results$Accuracy, 
                                                  decreasing = T),][1,]
  best_knn_models <- rbind(best_knn_models, tmp_best_model)
}


performance_knn$n_features <- as.factor(performance_knn$n_features)
best_knn_models$n_features <- as.factor(best_knn_models$n_features)

ggplot(data = performance_knn, 
       mapping = aes(x = k, y = Accuracy, color = n_features)) +
  geom_line(size = 1) +
  scale_x_continuous(breaks = k_grid_search) +
  theme_bw() +
  geom_point(data = best_knn_models, 
             mapping = aes(x = k, y = Accuracy, color = n_features), 
             size = 4)

```